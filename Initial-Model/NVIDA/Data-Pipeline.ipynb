{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import os\n",
    "import math\n",
    "import joblib\n",
    "from typing import Optional, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a227cd",
   "metadata": {},
   "source": [
    "### Data Pipeline for Loading and Sampling Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595942ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Utilities: save/load, sampling, inverse-transform, export ====\n",
    "import os\n",
    "import math\n",
    "import joblib\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "\n",
    "def save_gan(bundle_path: str,\n",
    "             G: nn.Module,\n",
    "             D: nn.Module,\n",
    "             preprocessor: ColumnTransformer,\n",
    "             meta: Optional[Dict[str, Any]] = None):\n",
    "    \"\"\"\n",
    "    Saves:\n",
    "      - {bundle_path}.pt  : torch checkpoints (G/D state_dicts + meta)\n",
    "      - {bundle_path}.prep: sklearn preprocessor (ColumnTransformer + helpful fields)\n",
    "    \"\"\"\n",
    "    ckpt = {\n",
    "        \"G_state\": G.state_dict(),\n",
    "        \"D_state\": D.state_dict(),\n",
    "        \"meta\": (meta or {}),\n",
    "    }\n",
    "    torch.save(ckpt, f\"{bundle_path}.pt\")\n",
    "\n",
    "    prep_bundle = {\n",
    "        \"preprocessor\": preprocessor,\n",
    "        # Nice-to-have fields if present:\n",
    "        \"feature_names_\": getattr(preprocessor, \"get_feature_names_out\", lambda: None)(),\n",
    "    }\n",
    "    joblib.dump(prep_bundle, f\"{bundle_path}.prep\")\n",
    "    print(f\"[save_gan] Wrote: {bundle_path}.pt  and  {bundle_path}.prep\")\n",
    "\n",
    "\n",
    "def load_gan(bundle_path: str,\n",
    "             latent_dim: int,\n",
    "             in_dim: int,\n",
    "             device: str = \"cpu\",\n",
    "             G_cls=Generator,\n",
    "             D_cls=Discriminator) -> Tuple[nn.Module, nn.Module, ColumnTransformer, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Recreates G/D modules, loads weights, and returns the fitted preprocessor & meta.\n",
    "    \"\"\"\n",
    "    ckpt = torch.load(f\"{bundle_path}.pt\", map_location=device)\n",
    "    G = G_cls(latent_dim, in_dim).to(device)\n",
    "    D = D_cls(in_dim).to(device)\n",
    "    G.load_state_dict(ckpt[\"G_state\"])\n",
    "    D.load_state_dict(ckpt[\"D_state\"])\n",
    "    G.eval(); D.eval()\n",
    "\n",
    "    prep_bundle = joblib.load(f\"{bundle_path}.prep\")\n",
    "    preprocessor = prep_bundle[\"preprocessor\"]\n",
    "    meta = ckpt.get(\"meta\", {})\n",
    "    print(f\"[load_gan] Loaded G/D and preprocessor from {bundle_path}.*\")\n",
    "    return G, D, preprocessor, meta\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_latent(n: int, latent_dim: int, device: str = \"cpu\", seed: Optional[int] = None) -> torch.Tensor:\n",
    "    if seed is not None:\n",
    "        g = torch.Generator(device=device)\n",
    "        g.manual_seed(seed)\n",
    "        return torch.randn((n, latent_dim), device=device, generator=g)\n",
    "    return torch.randn((n, latent_dim), device=device)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_synthetic(G: nn.Module,\n",
    "                     n_rows: int,\n",
    "                     latent_dim: int,\n",
    "                     device: str = \"cpu\",\n",
    "                     batch_size: int = 4096) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Samples in the GAN's feature space (i.e., AFTER preprocessing & scaling).\n",
    "    Returns a float32 tensor of shape [n_rows, in_dim] in [-1, 1] (because of Tanh).\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    out = []\n",
    "    remain = n_rows\n",
    "    while remain > 0:\n",
    "        b = min(remain, batch_size)\n",
    "        z = sample_latent(b, latent_dim, device=device)\n",
    "        x = G(z)\n",
    "        out.append(x.detach().cpu())\n",
    "        remain -= b\n",
    "    return torch.vstack(out)\n",
    "\n",
    "\n",
    "def inverse_to_dataframe(X: torch.Tensor,\n",
    "                         preprocessor: ColumnTransformer,\n",
    "                         original_columns: Optional[list] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Attempts to invert the ColumnTransformer (+ pipelines) back to a tidy DataFrame.\n",
    "    Works when transformers support inverse_transform (SimpleImputer, MinMaxScaler, OneHotEncoder do).\n",
    "    Falls back to a numpy array -> DataFrame if inverse_transform fails.\n",
    "    \"\"\"\n",
    "    X_np = X.detach().cpu().numpy()\n",
    "    try:\n",
    "        X_inv = preprocessor.inverse_transform(X_np)\n",
    "        # If original columns known, use them; else produce generic names\n",
    "        if original_columns is not None:\n",
    "            df = pd.DataFrame(X_inv, columns=original_columns)\n",
    "        else:\n",
    "            # best-effort: if the original DF shape is known from the preprocessor\n",
    "            # there's no universal way; we just number columns\n",
    "            df = pd.DataFrame(X_inv)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # Fallback: you still get the transformed array for further handling\n",
    "        print(f\"[inverse_to_dataframe] inverse_transform failed ({e}); returning transformed array as DataFrame\")\n",
    "        return pd.DataFrame(X_np)\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(G: nn.Module,\n",
    "                               preprocessor: ColumnTransformer,\n",
    "                               n_rows: int,\n",
    "                               latent_dim: int,\n",
    "                               device: str = \"cpu\",\n",
    "                               batch_size: int = 4096,\n",
    "                               original_columns: Optional[list] = None,\n",
    "                               seed: Optional[int] = None,\n",
    "                               return_tensor: bool = False) -> Tuple[pd.DataFrame, Optional[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    1) Samples in feature space from G\n",
    "    2) Inverse-transforms via the fitted preprocessor to get a DataFrame\n",
    "    3) Optionally returns the raw tensor in model space\n",
    "    \"\"\"\n",
    "    # Sample (optionally seed by setting global torch seed before calling)\n",
    "    X_t = sample_synthetic(G, n_rows, latent_dim, device=device, batch_size=batch_size)\n",
    "    # Invert to tabular space\n",
    "    df = inverse_to_dataframe(X_t, preprocessor, original_columns=original_columns)\n",
    "    return (df, X_t) if return_tensor else (df, None)\n",
    "\n",
    "\n",
    "def save_synthetic_csv(df: pd.DataFrame, path: str, index: bool = False):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    df.to_csv(path, index=index)\n",
    "    print(f\"[save_synthetic_csv] Wrote {len(df):,} rows to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "G_loaded, D_loaded, preproc, meta = load_gan(\n",
    "    \"./artifacts/loan_gan\",\n",
    "    latent_dim=latent_dim,\n",
    "    in_dim=in_dim,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Generate 10k synthetic rows\n",
    "df_synth, _ = generate_synthetic_dataset(\n",
    "    G_loaded,\n",
    "    preproc,\n",
    "    n_rows=10_000,\n",
    "    latent_dim=meta[\"latent_dim\"],\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "save_synthetic_csv(df_synth, \"./artifacts/loan_synth_10k.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
