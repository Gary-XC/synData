{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9505c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEVICE: privateuseone:1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/adam.py:226\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    216\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    217\u001b[39m         group,\n\u001b[32m    218\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m         state_steps,\n\u001b[32m    224\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/optimizer.py:161\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/adam.py:766\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    764\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/adam.py:534\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_lerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m torch._foreach_mul_(device_exp_avg_sqs, beta2)\n",
      "\u001b[31mRuntimeError\u001b[39m: Unknown error -2147467259",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 233\u001b[39m\n\u001b[32m    230\u001b[39m d_fake = D(fake.detach()); loss_fake = criterion(d_fake, fake_lab)\n\u001b[32m    232\u001b[39m (loss_real + loss_fake).backward()\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43moptD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# -- G step\u001b[39;00m\n\u001b[32m    236\u001b[39m optG.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    480\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    481\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    482\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     ret = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dynamo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     torch.set_grad_enabled(prev_grad)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/dml/lib/python3.12/site-packages/torch/_dynamo/decorators.py:140\u001b[39m, in \u001b[36mgraph_break\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m    Customize which functions TorchDynamo will exclude in the generated\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    graph and force a graph break on.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m    single `torch.add()` op.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _disallow_in_graph_helper(throw_if_not_allowed=\u001b[38;5;28;01mTrue\u001b[39;00m)(fn)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;129m@_disallow_in_graph_helper\u001b[39m(throw_if_not_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgraph_break\u001b[39m():\n\u001b[32m    142\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Force a graph break\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# DirectML Tabular GAN — GPU-Resident (manual batching)\n",
    "# ===========================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- Imports\n",
    "import random, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch_directml as dml\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Reproducibility\n",
    "# ---------------------------\n",
    "SEED = 999\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Device (prefer dGPU:1)\n",
    "# ---------------------------\n",
    "try:\n",
    "    DEVICE = dml.device(1)      # your dedicated GPU index; change if needed\n",
    "    _ = torch.ones(1, device=DEVICE)\n",
    "except Exception:\n",
    "    # fallback: try 0, else CPU\n",
    "    try:\n",
    "        DEVICE = dml.device(0); _ = torch.ones(1, device=DEVICE)\n",
    "    except Exception:\n",
    "        DEVICE = \"cpu\"\n",
    "print(\"Using DEVICE:\", DEVICE)\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2) Preprocessing helpers + Dataset (inverse)\n",
    "# --------------------------------------------\n",
    "def cap_rare_inplace(X: pd.DataFrame, cols, min_count=20, min_frac=None):\n",
    "    n = len(X)\n",
    "    for col in cols:\n",
    "        s = X[col].astype(str)\n",
    "        t = min_count if min_frac is None else max(min_count, int(min_frac * n))\n",
    "        vc = s.value_counts(dropna=False)\n",
    "        rare = vc[vc < t].index\n",
    "        X.loc[:, col] = s.where(~s.isin(rare), \"_OTHER_\")\n",
    "\n",
    "class AutoTabularDataset:\n",
    "    \"\"\"Simple holder with fitted preprocessor + tensors.\"\"\"\n",
    "    def __init__(self, dataframe: pd.DataFrame, target: str | None = None,\n",
    "                 min_count=100, min_frac=0.01):\n",
    "        df = dataframe.copy()\n",
    "\n",
    "        # Drop obvious IDs\n",
    "        id_like = [c for c in df.columns\n",
    "                   if c.lower().endswith(\"id\") or c.lower().endswith(\"_id\") or c.lower()==\"id\"]\n",
    "        if id_like: df = df.drop(columns=id_like)\n",
    "\n",
    "        # X/y split\n",
    "        if target is not None and target in df.columns:\n",
    "            y_raw = df[target]; X_raw = df.drop(columns=[target]).copy()\n",
    "        else:\n",
    "            y_raw = None; X_raw = df.copy()\n",
    "\n",
    "        # Types\n",
    "        self.num_cols = X_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.cat_cols = [c for c in X_raw.columns if c not in self.num_cols]\n",
    "\n",
    "        # Rare-cap\n",
    "        if self.cat_cols:\n",
    "            cap_rare_inplace(X_raw, self.cat_cols, min_count=min_count, min_frac=min_frac)\n",
    "\n",
    "        # Pipelines\n",
    "        num_pipe = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", MinMaxScaler(feature_range=(-1, 1))),\n",
    "        ])\n",
    "        try:\n",
    "            cat_pipe = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float32)),\n",
    "            ])\n",
    "        except TypeError:\n",
    "            cat_pipe = Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False, dtype=np.float32)),\n",
    "            ])\n",
    "\n",
    "        self.pre = ColumnTransformer(\n",
    "            transformers=[(\"num\", num_pipe, self.num_cols),\n",
    "                          (\"cat\", cat_pipe, self.cat_cols)],\n",
    "            remainder=\"drop\", verbose_feature_names_out=False\n",
    "        )\n",
    "\n",
    "        Xp = self.pre.fit_transform(X_raw).astype(np.float32)\n",
    "        self.X = torch.as_tensor(Xp, dtype=torch.float32, device=\"cpu\")\n",
    "\n",
    "        # One-hot group sizes (for inverse)\n",
    "        self.cat_group_sizes = []\n",
    "        if self.cat_cols:\n",
    "            oh: OneHotEncoder = self.pre.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "            for cats in oh.categories_:\n",
    "                self.cat_group_sizes.append(len(cats))\n",
    "\n",
    "    def _harden_onehots(self, X_fake_np: np.ndarray) -> np.ndarray:\n",
    "        if not self.cat_cols: return X_fake_np\n",
    "        out = X_fake_np.copy()\n",
    "        num_dim = len(self.num_cols)\n",
    "        start = num_dim\n",
    "        for g in self.cat_group_sizes:\n",
    "            if g <= 0: continue\n",
    "            block = out[:, start:start+g]\n",
    "            idx = np.argmax(block, axis=1)\n",
    "            block[:] = 0.0\n",
    "            block[np.arange(block.shape[0]), idx] = 1.0\n",
    "            out[:, start:start+g] = block\n",
    "            start += g\n",
    "        return out\n",
    "\n",
    "    def inverse_to_dataframe(self, X_fake: torch.Tensor) -> pd.DataFrame:\n",
    "        Xf = X_fake.detach().to(\"cpu\").numpy().astype(np.float32)\n",
    "        if self.num_cols:\n",
    "            num_dim = len(self.num_cols)\n",
    "            Xf[:, :num_dim] = np.clip(Xf[:, :num_dim], -1.0, 1.0)\n",
    "        Xf = self._harden_onehots(Xf)\n",
    "        try:\n",
    "            X_inv = self.pre.inverse_transform(Xf)\n",
    "            cols = self.num_cols + self.cat_cols\n",
    "            return pd.DataFrame(X_inv, columns=cols)\n",
    "        except Exception:\n",
    "            cols = [f\"f{i}\" for i in range(Xf.shape[1])]\n",
    "            return pd.DataFrame(Xf, columns=cols)\n",
    "\n",
    "# ------------------------\n",
    "# 3) Load data\n",
    "# ------------------------\n",
    "FILE_PATH = \"../data/Loan_default.csv\"\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "dataset = AutoTabularDataset(df, target=None, min_count=100, min_frac=0.01)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4) Move the WHOLE dataset to GPU once (big speedup)\n",
    "# ----------------------------------------------------\n",
    "X_device = dataset.X.to(DEVICE, non_blocking=True)  # one-time host→device copy\n",
    "N, in_dim = X_device.shape\n",
    "latent_dim = 64\n",
    "\n",
    "# ------------------------\n",
    "# 5) Models (heavier nets)\n",
    "# ------------------------\n",
    "width = 2048  # raise/lower based on VRAM\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, d), nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, z): return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, width), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(width, 1),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "G = Generator(latent_dim, in_dim).to(DEVICE)\n",
    "D = Discriminator(in_dim).to(DEVICE)\n",
    "\n",
    "# --------------------------------\n",
    "# 6) Loss, optimizers, (optional EMA)\n",
    "# --------------------------------\n",
    "criterion = nn.MSELoss()  # LSGAN: real=1, fake=0\n",
    "optD = optim.Adam(D.parameters(), lr=3e-4, betas=(0.0, 0.99))\n",
    "optG = optim.Adam(G.parameters(), lr=1e-4, betas=(0.0, 0.99))\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model: nn.Module, decay: float = 0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "        self.keys = list(self.shadow.keys()); self.model = model\n",
    "    @torch.no_grad()\n",
    "    def update(self):\n",
    "        msd = self.model.state_dict()\n",
    "        for k in self.keys:\n",
    "            self.shadow[k].lerp_(msd[k].detach(), 1.0 - self.decay)\n",
    "    def copy_to(self, model: nn.Module): model.load_state_dict(self.shadow, strict=False)\n",
    "\n",
    "ema = EMA(G, decay=0.999)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) GPU-resident training loop\n",
    "# -----------------------------\n",
    "batch_size = 4096   # try 2048 if it fits; reduce on OOM\n",
    "num_epochs = 30\n",
    "\n",
    "# Preallocate labels max size (slice each step)\n",
    "ones_full  = torch.ones(batch_size, 1, device=DEVICE)\n",
    "zeros_full = torch.zeros(batch_size, 1, device=DEVICE)\n",
    "\n",
    "G.train(); D.train()\n",
    "torch.set_grad_enabled(True)     # global switch back ON\n",
    "for epoch in range(num_epochs):\n",
    "    # shuffle indices ON GPU\n",
    "    perm = torch.randperm(N, device=DEVICE)\n",
    "    for i in range(0, N, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        real = X_device.index_select(0, idx)\n",
    "        bsz = real.size(0)\n",
    "\n",
    "        real_lab = ones_full[:bsz]\n",
    "        fake_lab = zeros_full[:bsz]\n",
    "\n",
    "        # -- D step\n",
    "        optD.zero_grad(set_to_none=True)\n",
    "        d_real = D(real); loss_real = criterion(d_real, real_lab)\n",
    "\n",
    "        z = torch.randn(bsz, latent_dim, device=DEVICE)\n",
    "        fake = G(z)\n",
    "        d_fake = D(fake.detach()); loss_fake = criterion(d_fake, fake_lab)\n",
    "\n",
    "        (loss_real + loss_fake).backward()\n",
    "        optD.step()\n",
    "\n",
    "        # -- G step\n",
    "        optG.zero_grad(set_to_none=True)\n",
    "        g_loss = criterion(D(fake), real_lab)\n",
    "        g_loss.backward()\n",
    "        optG.step()\n",
    "        ema.update()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:3d}: D_real={loss_real.item():.4f}  D_fake={loss_fake.item():.4f}  G={g_loss.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8) Sampling + inverse back to DF\n",
    "# -------------------------------\n",
    "G_eval = Generator(latent_dim, in_dim).to(DEVICE)\n",
    "ema.copy_to(G_eval); G_eval.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, latent_dim, device=DEVICE)\n",
    "    X_fake = G_eval(z)\n",
    "\n",
    "synthetic_df = dataset.inverse_to_dataframe(X_fake)\n",
    "synthetic_df.head(100).to_csv(\"synthetic_preview.csv\", index=False)\n",
    "print(\"Saved synthetic_preview.csv (first 100 rows)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
